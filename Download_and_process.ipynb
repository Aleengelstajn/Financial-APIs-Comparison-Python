{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This jupyter uses the following libraries:\n",
    "* pandas\n",
    "* pickle\n",
    "* functools\n",
    "* requests\n",
    "* urllib\n",
    "* finnhub\n",
    "* nasdaqdatalink\n",
    "* certifi\n",
    "\n",
    "So if you don't have any of these, go ahead and install them"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------\n",
    "## $$FUNCTIONS$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are functions for each API . Some of the request come straight foward and are easy to store in dataframe format. Others are built from 3 different requests for __Income Statement__, __Balance-Sheet__ and __Cash-Flow__. Each function will download, transform and store in a .csv file the dataframe so they can be read in `complete_process()` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eod(ticker):\n",
    "    ''' Libraries ''' \n",
    "    import requests\n",
    "    import os\n",
    "    import pandas as pd\n",
    "    from urllib.request import urlopen\n",
    "    import functools as ft\n",
    "    from eodhd import APIClient\n",
    "    import os\n",
    "    from eod import EodHistoricalData\n",
    "    import pickle\n",
    "\n",
    "    '''Request'''\n",
    "    api_key = '60ee983ba13887.41798715'\n",
    "    client = EodHistoricalData(api_key)\n",
    "    data = client.get_fundamental_equity(f'{ticker}')\n",
    "    data['Financials'].keys()\n",
    "\n",
    "    ''' Data Transformation'''\n",
    "    tabla = pd.read_excel('Merge.xlsx')\n",
    "    columns = ['date'] + list(tabla.tag_eod)\n",
    "    '''\n",
    "    Balance Sheet\n",
    "    '''\n",
    "    df = pd.DataFrame(data['Financials']['Balance_Sheet'])\n",
    "    df_balance = pd.DataFrame()\n",
    "    for j in range(len(df)):\n",
    "        try:\n",
    "            df2 = pd.DataFrame(df.iloc[j].yearly, index=[0])\n",
    "            df_balance = pd.concat([df_balance, df2], axis=0)\n",
    "        except:\n",
    "            pass\n",
    "    '''\n",
    "    Cash Flow\n",
    "    '''\n",
    "    df = pd.DataFrame(data['Financials']['Cash_Flow'])\n",
    "    df_cash = pd.DataFrame()\n",
    "    for k in range(len(df)):\n",
    "        try:\n",
    "            df2 = pd.DataFrame(df.iloc[k].yearly, index=[0])\n",
    "            df_cash = pd.concat([df_cash, df2], axis=0)\n",
    "        except:\n",
    "            pass\n",
    "    '''\n",
    "    Income Statement\n",
    "    '''\n",
    "    df = pd.DataFrame(data['Financials']['Income_Statement'])\n",
    "    df_income = pd.DataFrame()\n",
    "    for p in range(len(df)):\n",
    "        try:\n",
    "            df2 = pd.DataFrame(df.iloc[p].yearly, index=[0])\n",
    "            df_income = pd.concat([df_income, df2], axis=0)\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    dfs = [df_cash, df_income, df_balance]\n",
    "    df_final = ft.reduce(lambda left, right: pd.merge(left, right, on='date'), dfs)\n",
    "    df_final['date']= pd.to_datetime(df_final.date)\n",
    "    df_final['date']= df_final.date.dt.strftime('%Y-%m')\n",
    "    df_final = df_final[columns]\n",
    "    df_final.insert(1, 'ticker', ticker)\n",
    "    ''' Renaming columns'''\n",
    "    with open('saved_dictionary.pkl', 'rb') as f:\n",
    "        dict = pickle.load(f)\n",
    "    df_final.rename(columns=dict['eod'], inplace=True)\n",
    "\n",
    "\n",
    "    df_final.to_csv('Data\\eod.csv')\n",
    "    return df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def alpha_vantage(ticker, period='annualReports'):\n",
    "    ''' Libraries ''' \n",
    "    import requests\n",
    "    import os\n",
    "    import pandas as pd\n",
    "    import pickle\n",
    "\n",
    "    from urllib.request import urlopen\n",
    "    import functools as ft\n",
    "\n",
    "    ''' taggin function'''\n",
    "    def tag(nombre, api):\n",
    "        name = nombre + '_'+api\n",
    "        return name\n",
    "        \n",
    "\n",
    "    ''' Request'''\n",
    "    url = f'https://www.alphavantage.co/query?function=Cash_flow&symbol={ticker}&apikey=6DWJBYP02X4S13GL'\n",
    "    r = requests.get(url)\n",
    "    data = r.json()\n",
    "    df_cash = pd.DataFrame(data[period])\n",
    "    \n",
    "\n",
    "    url = f'https://www.alphavantage.co/query?function=Balance_Sheet&symbol={ticker}&apikey=6DWJBYP02X4S13GL'\n",
    "    r = requests.get(url)\n",
    "    data = r.json()\n",
    "    df_balance = pd.DataFrame(data[period])\n",
    "\n",
    "    url = f'https://www.alphavantage.co/query?function=Income_Statement&symbol={ticker}&apikey=6DWJBYP02X4S13GL'\n",
    "    r = requests.get(url)\n",
    "    data = r.json()\n",
    "    df_income = pd.DataFrame(data[period])\n",
    "\n",
    "    dfs = [ df_cash, df_balance , df_income]\n",
    "    df_alpha = ft.reduce(lambda left, right: pd.merge(left, right, on='fiscalDateEnding'),dfs )\n",
    "    \n",
    "    tabla = pd.read_excel(r'Merge.xlsx')\n",
    "    columnas_Alpha = ['fiscalDateEnding'] + tabla.tag_alpha.tolist()\n",
    "    \n",
    "    df_alpha = df_alpha[columnas_Alpha]\n",
    "    df_alpha = df_alpha.loc[:, ~df_alpha.columns.duplicated()]\n",
    "\n",
    "    df_alpha.fiscalDateEnding = pd.to_datetime(df_alpha.fiscalDateEnding)\n",
    "    \n",
    "    \n",
    "    ''' Renaming columns'''\n",
    "    with open('saved_dictionary.pkl', 'rb') as f:\n",
    "        dict = pickle.load(f)\n",
    "    df_alpha.rename(columns=dict['alpha_vantage'], inplace=True)\n",
    "    df_alpha.insert(0,'ticker' , f'{ticker}')\n",
    "    df_alpha.insert(1, 'date',df_alpha.fiscalDateEnding.dt.strftime('%Y-%m'))\n",
    "    \n",
    "    df_alpha.to_csv('Data\\\\alpha.csv')\n",
    "    return df_alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tiingo(ticker):\n",
    "        ''' Libraries ''' \n",
    "        import requests\n",
    "        import os\n",
    "        import pandas as pd\n",
    "        import pickle\n",
    "\n",
    "        from urllib.request import urlopen\n",
    "        import requests\n",
    "        ''' Reqyuest ''' \n",
    "        headers = {\n",
    "                'Content-Type': 'application/json',\n",
    "                'Authorization' : 'Token 41215ee240ce2f36eb1cd500d85f8663801366e2'\n",
    "                }\n",
    "        requestResponse = requests.get(f\"https://api.tiingo.com/tiingo/fundamentals/{ticker}/statements\",\n",
    "                                        headers=headers)\n",
    "        df_tiingo = pd.DataFrame(requestResponse.json())\n",
    "        \n",
    "        tabla = pd.read_excel(r'Merge.xlsx')\n",
    "        columnas_tiingo = ['ticker', 'date', 'quarter'] +  tabla.tag_tiingo.tolist()\n",
    "        columnas_tiingo.remove('opMargin')\n",
    "\n",
    "\n",
    "        ''' Transform ''' \n",
    "        df_main = pd.DataFrame()\n",
    "        for j in range(len(df_tiingo)): # This iterator finds all rows\n",
    "        \n",
    "                dict_tiingo = {}\n",
    "                '''incomeStatement''' \n",
    "                for i in range(len(df_tiingo.iloc[j]['statementData']['incomeStatement'])): # This iterator finds all collumns within this dictionary\n",
    "                        column_name = df_tiingo.iloc[j]['statementData']['incomeStatement'][i]['dataCode']\n",
    "                        value       = df_tiingo.iloc[j]['statementData']['incomeStatement'][i]['value'] \n",
    "                        dict_tiingo[column_name]=value\n",
    "                #print(j , len(dict_tiingo))\n",
    "\n",
    "                ''' BalanceSheet'''\n",
    "                for i in range(len(df_tiingo.iloc[j]['statementData']['balanceSheet'])):\n",
    "                        column_name = df_tiingo.iloc[j]['statementData']['balanceSheet'][i]['dataCode']\n",
    "                        value       = df_tiingo.iloc[j]['statementData']['balanceSheet'][i]['value'] \n",
    "                        dict_tiingo[column_name]=value\n",
    "                        \n",
    "                #print(j , len(dict_tiingo))\n",
    "\n",
    "                '''CashFlow'''\n",
    "                for i in range(len(df_tiingo.iloc[j]['statementData']['cashFlow'])):\n",
    "                        column_name = df_tiingo.iloc[j]['statementData']['cashFlow'][i]['dataCode']\n",
    "                        value       = df_tiingo.iloc[j]['statementData']['cashFlow'][i]['value'] \n",
    "                        dict_tiingo[column_name]=value\n",
    "                        \n",
    "                #print(j , len(dict_tiingo), df_tiingo.iloc[j].date, df_tiingo.iloc[j].quarter)\n",
    "                df = pd.DataFrame(dict_tiingo, index=[1])\n",
    "                columns = df.columns.sort_values()\n",
    "                df = df[columns]\n",
    "                df.insert(0, 'ticker', f'{ticker}')\n",
    "                df.insert(1, 'date',df_tiingo.iloc[j].date )\n",
    "                df.insert(2, 'quarter', df_tiingo.iloc[j].quarter)\n",
    "                df_main = pd.concat([df_main, df], axis=0)\n",
    "                df_main = df_main[df_main.quarter !=4]\n",
    "\n",
    "                df_main['date'] = pd.to_datetime(df_main.date)\n",
    "                df_main['date'] = df_main.date.dt.strftime('%Y-%m')\n",
    "        df_main = df_main[columnas_tiingo]\n",
    "        ''' Renaming columns'''\n",
    "        with open('saved_dictionary.pkl', 'rb') as f:\n",
    "                dict = pickle.load(f)\n",
    "        df_main.rename(columns=dict['tiingo'], inplace=True)\n",
    "        df_main.to_csv('Data\\\\tiingo.csv')\n",
    "        return df_main\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def finnhub(ticker):\n",
    "\n",
    "    ''' Libraries ''' \n",
    "    import requests\n",
    "    import os\n",
    "    import pandas as pd\n",
    "    import pickle\n",
    "\n",
    "    from urllib.request import urlopen\n",
    "    import functools as ft\n",
    "    import finnhub\n",
    "    finnhub_client = finnhub.Client(api_key='cagpcp2ad3i02fchaga0')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    '''\n",
    "    Balance Sheet\n",
    "    '''\n",
    "    data = finnhub_client.financials(f'{ticker}', 'bs', 'annual')\n",
    "    df_balance = pd.DataFrame()\n",
    "    for j in range(len(data['financials'])):\n",
    "        df = pd.DataFrame(data['financials'][j], index=[1])\n",
    "        df_balance = pd.concat([df_balance, df], axis=0)\n",
    "    cols = list(df_balance.columns)\n",
    "    cols.remove('period')\n",
    "    cols.insert(0,'period')\n",
    "    df_balance = df_balance\n",
    "    #display(df_balance[cols].head(3))\n",
    "\n",
    "    ''' \n",
    "    Income Statement\n",
    "    ''' \n",
    "    data = finnhub_client.financials(f'{ticker}', 'ic', 'annual')\n",
    "    df_income = pd.DataFrame()\n",
    "    for k in range(len(data['financials'])):\n",
    "        df = pd.DataFrame(data['financials'][k], index=[1])\n",
    "        df_income = pd.concat([df_income, df], axis=0)\n",
    "    cols = list(df_income.columns)\n",
    "    cols.remove('period')\n",
    "    cols.insert(0,'period')\n",
    "    df_income = df_income[cols]\n",
    "    #display(df_income.head(3))\n",
    "\n",
    "    '''\n",
    "    Cash Flow\n",
    "    ''' \n",
    "    data = finnhub_client.financials(f'{ticker}', 'cf', 'annual')\n",
    "    df_cash = pd.DataFrame()\n",
    "    for q in range(len(data['financials'])):\n",
    "        try:\n",
    "            df = pd.DataFrame(data['financials'][q], index=[1])\n",
    "            df_cash  = pd.concat([df_cash, df], axis=0)\n",
    "        except:\n",
    "            print(q)\n",
    "            pass\n",
    "    cols = list(df_cash.columns)\n",
    "    cols.remove('period')\n",
    "    cols.insert(0, 'period')\n",
    "    df_cash = df_cash[cols]\n",
    "    #display(df_cash.head(3))\n",
    "\n",
    "    dfs = [df_cash, df_balance, df_income] \n",
    "    df_final = ft.reduce(lambda left, right: pd.merge(left, right, on='period'), dfs)\n",
    "\n",
    "    df_final['date'] = pd.to_datetime(df_final['period'])\n",
    "    df_final['date'] = df_final.date.dt.strftime('%Y-%m')\n",
    "    df_final['ticker'] = ticker\n",
    "    tabla = pd.read_excel('Merge.xlsx')\n",
    "    columns = ['date', 'ticker'] + list(tabla.tag_finn)\n",
    "    ''' Renaming columns'''\n",
    "    df_final = df_final[columns]\n",
    "    with open('saved_dictionary.pkl', 'rb') as f:\n",
    "        dict = pickle.load(f)\n",
    "    df_final.rename(columns=dict['finnhub'], inplace=True)\n",
    "\n",
    "    df_final.to_csv('Data\\\\finnhub.csv') \n",
    "    return df_final\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sharadar(ticker):\n",
    "    import requests\n",
    "    import os\n",
    "    import pandas as pd\n",
    "    from urllib.request import urlopen\n",
    "    import nasdaqdatalink\n",
    "    import pickle\n",
    "\n",
    "\n",
    "    nasdaqdatalink.ApiConfig.api_key = \"rxxWsjphD1YghSYo-LWD\"\n",
    "      \n",
    "    def tag(nombre, api):\n",
    "        name = nombre + '_'+api\n",
    "        return name\n",
    "\n",
    "    tabla = pd.read_excel(r'Merge.xlsx')\n",
    "    columnas_sharadar = ['ticker', 'reportperiod', 'datekey'] +  tabla.tag_sharadar.tolist()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    df_sharadar = nasdaqdatalink.get_table('SHARADAR/SF1', ticker=f'{ticker}')    \n",
    "    df_sharadar = df_sharadar[columnas_sharadar]\n",
    "\n",
    "\n",
    "    ''' datekey to date_time type''' \n",
    "    df_sharadar.datekey = pd.to_datetime(df_sharadar.datekey)\n",
    "    df_sharadar.insert(0, 'date', df_sharadar.datekey.dt.strftime('%Y-%m'))\n",
    "    ''' Renaming columns'''\n",
    "    with open('saved_dictionary.pkl', 'rb') as f:\n",
    "        dict = pickle.load(f)\n",
    "    df_sharadar.rename(columns=dict['sharadar'], inplace=True)\n",
    "    df_sharadar.drop_duplicates(inplace=True)\n",
    "    df_sharadar.drop_duplicates('date', inplace=True)\n",
    "    df_sharadar.to_csv('Data\\\\sharadar.csv')\n",
    "    return df_sharadar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def financial_model(ticker):\n",
    "    ''' Libraries ''' \n",
    "    import certifi\n",
    "    import json\n",
    "    import requests\n",
    "    import os\n",
    "    import pandas as pd\n",
    "    import pickle\n",
    "    from urllib.request import urlopen\n",
    "    import functools as ft\n",
    "\n",
    "    \n",
    "    def get_jsonparsed_data(url):\n",
    "        \"\"\"\n",
    "        Receive the content of ``url``, parse it as JSON and return the object.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        url : str\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        dict\n",
    "        \"\"\"\n",
    "        response = urlopen(url, cafile=certifi.where())\n",
    "        data = response.read().decode(\"utf-8\")\n",
    "        return json.loads(data)\n",
    "\n",
    "    url_income = f'https://financialmodelingprep.com/api/v3/income-statement/{ticker}?apikey=ba8a6d3ac5e7ca36fc2ee9be73394ef1'\n",
    "    url_cash = f'https://financialmodelingprep.com/api/v3/cash-flow-statement/{ticker}?apikey=ba8a6d3ac5e7ca36fc2ee9be73394ef1'\n",
    "    url_balance = f'https://financialmodelingprep.com/api/v3/balance-sheet-statement/{ticker}?apikey=ba8a6d3ac5e7ca36fc2ee9be73394ef1'\n",
    "\n",
    "    income = get_jsonparsed_data(url_income)\n",
    "    cash = get_jsonparsed_data(url_cash)\n",
    "    balance = get_jsonparsed_data(url_balance)\n",
    "\n",
    "    tabla = pd.read_excel('Merge.xlsx')\n",
    "    columns = ['date', 'symbol'] +list(tabla.tag_finmodprep)\n",
    "    columns.remove('inventory')\n",
    "    columns.append('inventory_y')\n",
    "\n",
    "    df_income=pd.DataFrame()\n",
    "    for j in range(len(income)):\n",
    "        df= pd.DataFrame(income[j], index=[1])\n",
    "        df_income = pd.concat([df_income, df], axis=0)\n",
    "        \n",
    "\n",
    "    df_cash = pd.DataFrame()\n",
    "    for i in range(len(cash)):\n",
    "        df = pd.DataFrame(cash[i], index=[1])\n",
    "        df_cash = pd.concat([df_cash, df], axis=0)\n",
    "\n",
    "    df_balance = pd.DataFrame()\n",
    "    for k in range(len(balance)):\n",
    "        df = pd.DataFrame(balance[k], index=[1])\n",
    "        df_balance = pd.concat([df_balance, df], axis=0)\n",
    "\n",
    "    dfs = [df_cash, df_income, df_balance]\n",
    "    df_final = ft.reduce(lambda left, right: pd.merge(left, right, on='date'), dfs)\n",
    "    df_final = df_final[columns]\n",
    "    df_final.rename(columns={'inventory_y': 'inventory', 'symbol': 'ticker'}, inplace=True)\n",
    "\n",
    "    df_final['date'] = pd.to_datetime(df_final.date)\n",
    "    df_final.date = df_final.date.dt.strftime('%Y-%m')\n",
    "    \n",
    "    ''' Renaming columns'''\n",
    "    with open('saved_dictionary.pkl', 'rb') as f:\n",
    "        dict = pickle.load(f)\n",
    "    df_final.rename(columns=dict['financial_model'], inplace=True)\n",
    "    df_final.to_csv('Data\\\\financial_model.csv')\n",
    "\n",
    "\n",
    "    return df_final.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $$ MERGE \\space FUNCTION $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`complete_process(ticker): ` takes a symbol _(between __\"\"__, don't forget)_ and uses all functions in a multithread process. \n",
    "\n",
    "The process works as follows:\n",
    "* Each function will download, transform and store each API's dataframe\n",
    "* The columns will be renamed after _saved_dictionary.pkl_ file\n",
    "* The dataframe's columns will be reorganized after _Merge2.xlsx_ file so the values can be compared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def complete_process(ticker):\n",
    "    import pandas as pd \n",
    "    import functools as ft\n",
    "    import threading \n",
    "\n",
    "    eod_th = threading.Thread(target=eod, args=(ticker, ))\n",
    "    alpha_th = threading.Thread(target=alpha_vantage, args=(ticker,'quarterlyReports'))\n",
    "    tiingo_th = threading.Thread(target=tiingo,args=(ticker, ))\n",
    "    finnhub_th = threading.Thread(target=finnhub, args=(ticker, ))\n",
    "    sharadar_th = threading.Thread(target=sharadar, args=(ticker, ))\n",
    "    financial_th = threading.Thread(target=financial_model , args=(ticker, ))\n",
    "\n",
    "    ''' API REQUESTS | Each function works in multithread process'''\n",
    "    eod_th.start()\n",
    "    alpha_th.start()\n",
    "    tiingo_th.start()\n",
    "    finnhub_th.start()\n",
    "    sharadar_th.start()\n",
    "    financial_th.start()\n",
    "\n",
    "\n",
    "    eod_th.join()\n",
    "    alpha_th.join()\n",
    "    tiingo_th.join()\n",
    "    finnhub_th.join()\n",
    "    sharadar_th.join()\n",
    "    financial_th.join()\n",
    "\n",
    "    \n",
    "\n",
    "    '''Sorting columns using Merge2 excel file '''\n",
    "    \n",
    "    Merge2 = pd.read_excel('Merge2.xlsx')\n",
    "    Merge2.drop(columns='Unnamed: 0' , inplace=True)\n",
    "    lists = Merge2.to_numpy().tolist()\n",
    "    columnas_ordenadas = ['date', 'ticker']\n",
    "    \n",
    "    for sublist in lists:\n",
    "        for item in sublist:\n",
    "            columnas_ordenadas.append(item)\n",
    "\n",
    "\n",
    "    ''' Reading each file'''\n",
    "    eod_csv = pd.read_csv('Data\\\\eod.csv')\n",
    "    \n",
    "    alpha_csv = pd.read_csv('Data\\\\alpha.csv')\n",
    "    financial_model_csv = pd.read_csv('Data\\\\financial_model.csv')\n",
    "    finnhub_csv = pd.read_csv('Data\\\\finnhub.csv')\n",
    "    sharadar_csv = pd.read_csv('Data\\\\sharadar.csv')\n",
    "    tiingo_csv = pd.read_csv('Data\\\\tiingo.csv')\n",
    "\n",
    "    dfs = [eod_csv, alpha_csv, financial_model_csv, finnhub_csv, sharadar_csv, tiingo_csv]\n",
    "    dfs_name = ['eod_csv', 'alpha_csv', 'financial_model_csv', 'finnhub_csv', 'sharadar_csv', 'tiingo_csv']\n",
    "    ''' table with dataframes shapes'''\n",
    "    shapes = pd.DataFrame(columns=['API', 'Rows'])\n",
    "    for i in range(len(dfs)):\n",
    "        shapes.loc[len(shapes.index)] = [dfs_name[i], dfs[i].shape[0]]\n",
    "    display(shapes)\n",
    "    \n",
    "\n",
    "    ''' Merging all together on DATE and TICKER'''\n",
    "    df_merge = ft.reduce(lambda left, right: pd.merge(left, right, on=['date', 'ticker']), dfs) \n",
    "    \n",
    "   \n",
    "    ''' Giving the final dataframe the order from Merge2 file'''\n",
    "    df_merge =df_merge[columnas_ordenadas].drop_duplicates()\n",
    "\n",
    "    # Exporting this to excel Merge_raw\n",
    "    df_merge.to_excel('Data\\\\Merge_raw.xlsx')\n",
    "    return df_merge\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KNL\\AppData\\Local\\Temp\\ipykernel_384\\3375051500.py:25: DeprecationWarning: cafile, capath and cadefault are deprecated, use a custom context instead.\n",
      "  response = urlopen(url, cafile=certifi.where())\n",
      "C:\\Users\\KNL\\AppData\\Local\\Temp\\ipykernel_384\\3375051500.py:25: DeprecationWarning: cafile, capath and cadefault are deprecated, use a custom context instead.\n",
      "  response = urlopen(url, cafile=certifi.where())\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>API</th>\n",
       "      <th>Rows</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>eod_csv</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>alpha_csv</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>financial_model_csv</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>finnhub_csv</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sharadar_csv</td>\n",
       "      <td>196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>tiingo_csv</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   API Rows\n",
       "0              eod_csv   34\n",
       "1            alpha_csv   20\n",
       "2  financial_model_csv   34\n",
       "3          finnhub_csv   38\n",
       "4         sharadar_csv  196\n",
       "5           tiingo_csv   12"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KNL\\AppData\\Local\\Temp\\ipykernel_384\\4263719236.py:62: FutureWarning: Passing 'suffixes' which cause duplicate columns {'Unnamed: 0_x'} in the result is deprecated and will raise a MergeError in a future version.\n",
      "  df_merge = ft.reduce(lambda left, right: pd.merge(left, right, on=['date', 'ticker']), dfs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>ticker</th>\n",
       "      <th>totalAssets_tiingo</th>\n",
       "      <th>totalAssets_alpha</th>\n",
       "      <th>totalAssets_eod</th>\n",
       "      <th>totalAssets_finnhub</th>\n",
       "      <th>assets_sharadar</th>\n",
       "      <th>totalAssets_financial</th>\n",
       "      <th>totalLiabilities_tiingo</th>\n",
       "      <th>totalLiabilities_alpha</th>\n",
       "      <th>...</th>\n",
       "      <th>capitalExpenditures_eod</th>\n",
       "      <th>capex_finnhub</th>\n",
       "      <th>capex_sharadar</th>\n",
       "      <th>capitalExpenditure_financial</th>\n",
       "      <th>equity_tiingo</th>\n",
       "      <th>totalShareholderEquity_alpha</th>\n",
       "      <th>totalStockholderEquity_eod</th>\n",
       "      <th>liabilitiesShareholdersEquity_finnhub</th>\n",
       "      <th>equity_sharadar</th>\n",
       "      <th>totalStockholdersEquity_financial</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-09</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>3.527550e+11</td>\n",
       "      <td>352755000000</td>\n",
       "      <td>3.527550e+11</td>\n",
       "      <td>352755</td>\n",
       "      <td>3.527550e+11</td>\n",
       "      <td>352755000000</td>\n",
       "      <td>3.020830e+11</td>\n",
       "      <td>302083000000</td>\n",
       "      <td>...</td>\n",
       "      <td>10708000000</td>\n",
       "      <td>-10708</td>\n",
       "      <td>-1.070800e+10</td>\n",
       "      <td>-10708000000</td>\n",
       "      <td>5.067200e+10</td>\n",
       "      <td>50672000000</td>\n",
       "      <td>5.067200e+10</td>\n",
       "      <td>352755</td>\n",
       "      <td>5.067200e+10</td>\n",
       "      <td>50672000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-09</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>3.510020e+11</td>\n",
       "      <td>351002000000</td>\n",
       "      <td>3.510020e+11</td>\n",
       "      <td>351002</td>\n",
       "      <td>3.510020e+11</td>\n",
       "      <td>351002000000</td>\n",
       "      <td>2.879120e+11</td>\n",
       "      <td>287912000000</td>\n",
       "      <td>...</td>\n",
       "      <td>11085000000</td>\n",
       "      <td>-11085</td>\n",
       "      <td>-1.108500e+10</td>\n",
       "      <td>-11085000000</td>\n",
       "      <td>6.309000e+10</td>\n",
       "      <td>63090000000</td>\n",
       "      <td>6.309000e+10</td>\n",
       "      <td>351002</td>\n",
       "      <td>6.309000e+10</td>\n",
       "      <td>63090000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-09</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>3.238880e+11</td>\n",
       "      <td>323888000000</td>\n",
       "      <td>3.238880e+11</td>\n",
       "      <td>323888</td>\n",
       "      <td>3.238880e+11</td>\n",
       "      <td>323888000000</td>\n",
       "      <td>2.585490e+11</td>\n",
       "      <td>258549000000</td>\n",
       "      <td>...</td>\n",
       "      <td>7309000000</td>\n",
       "      <td>-7309</td>\n",
       "      <td>-7.309000e+09</td>\n",
       "      <td>-7309000000</td>\n",
       "      <td>6.533900e+10</td>\n",
       "      <td>65339000000</td>\n",
       "      <td>6.533900e+10</td>\n",
       "      <td>323888</td>\n",
       "      <td>6.533900e+10</td>\n",
       "      <td>65339000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 134 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      date ticker  totalAssets_tiingo  totalAssets_alpha  totalAssets_eod  \\\n",
       "0  2022-09   AAPL        3.527550e+11       352755000000     3.527550e+11   \n",
       "1  2021-09   AAPL        3.510020e+11       351002000000     3.510020e+11   \n",
       "2  2020-09   AAPL        3.238880e+11       323888000000     3.238880e+11   \n",
       "\n",
       "   totalAssets_finnhub  assets_sharadar  totalAssets_financial  \\\n",
       "0               352755     3.527550e+11           352755000000   \n",
       "1               351002     3.510020e+11           351002000000   \n",
       "2               323888     3.238880e+11           323888000000   \n",
       "\n",
       "   totalLiabilities_tiingo  totalLiabilities_alpha  ...  \\\n",
       "0             3.020830e+11            302083000000  ...   \n",
       "1             2.879120e+11            287912000000  ...   \n",
       "2             2.585490e+11            258549000000  ...   \n",
       "\n",
       "   capitalExpenditures_eod  capex_finnhub  capex_sharadar  \\\n",
       "0              10708000000         -10708   -1.070800e+10   \n",
       "1              11085000000         -11085   -1.108500e+10   \n",
       "2               7309000000          -7309   -7.309000e+09   \n",
       "\n",
       "   capitalExpenditure_financial  equity_tiingo  totalShareholderEquity_alpha  \\\n",
       "0                  -10708000000   5.067200e+10                   50672000000   \n",
       "1                  -11085000000   6.309000e+10                   63090000000   \n",
       "2                   -7309000000   6.533900e+10                   65339000000   \n",
       "\n",
       "   totalStockholderEquity_eod  liabilitiesShareholdersEquity_finnhub  \\\n",
       "0                5.067200e+10                                 352755   \n",
       "1                6.309000e+10                                 351002   \n",
       "2                6.533900e+10                                 323888   \n",
       "\n",
       "   equity_sharadar  totalStockholdersEquity_financial  \n",
       "0     5.067200e+10                        50672000000  \n",
       "1     6.309000e+10                        63090000000  \n",
       "2     6.533900e+10                        65339000000  \n",
       "\n",
       "[3 rows x 134 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "complete_process('AAPL')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So this is exported to __Merge_raw.xlsx__ (this file shoulnd't be opened)\n",
    "\n",
    "The analysis occurs in other excel file, which is __Excel_merge.xlsx__ through _\"Obtain data\"_, so you can update _Merge_raw_ without having to close the file.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "006c2b932914ff8e95f30e749041e4b399d36857f00ee48d79cb79341a100acd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
